---
title: "大语言模型能否成为博弈论中的理性玩家？一个系统性的分析"
collection: 报告
type: "报告"
permalink: /talks/2024-01-03-talk
venue: "智源社区"
date: 2024-01-03
location: "线上活动"
---

感谢智源社区邀请，我在[青源TALK第117期](https://event.baai.ac.cn/live/742)报告了我的[研究](https://arxiv.org/abs/2312.05488)，该研究发表在AAAI 2024。

![poster_青源](https://github.com/FCY36/FCY36.github.io/blob/master/files/talks/2024-01-03-talk/poster_%E9%9D%92%E6%BA%90.jpg)

博弈论作为一种分析工具，在社会科学研究中经常被用来分析人类行为。由于大语言模型（LLMs）的行为与人类高度一致，一个有前景的研究方向是在博弈实验中使用LLMs来替代人类，从而促进社会科学领域的研究。然而，尽管对LLMs与博弈论的结合进行了大量实证研究，LLMs在博弈论中的能力边界仍不清晰。在本研究中，我们致力于系统地分析博弈论背景下的LLMs。

具体来说，理性作为博弈论的基本原则，是评价玩家行为的标准——建立明确的期望、精炼对不确定性的信念、做出最优行动。因此，我们选择了三个经典博弈（独裁者博弈、剪刀石头布和环网博弈）来分析LLMs在这三个方面的理性程度。实验结果表明，即使是目前最先进的LLM（GPT-4），在博弈论方面与人类相比也有很大差距。例如，LLMs难以建立基于不常见偏好的期望，无法从许多简单模式中精炼信念，并且在做出行动时可能会忽略或修改已经提炼的信念。因此，我们认为在社会科学领域的博弈实验中引入LLMs应更加谨慎。

报告的[slides](https://github.com/FCY36/FCY36.github.io/blob/master/files/talks/2024-01-03-talk/slides_%E9%9D%92%E6%BA%90.pdf)

[关于报告的更多信息](https://event.baai.ac.cn/live/742)
